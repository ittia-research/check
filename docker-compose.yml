services:
  check:
    image: ittia/check:remote
    container_name: check
    env_file:
      - ./infra/env.d/check
    ports:
      - 8000:8000
    restart: always
    
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - /data/volumes/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: always

  # Infinity supports embedding and rerank models, v2 version supports serving multiple models
  infinity:
    image: michaelf34/infinity:latest
    container_name: infinity
    ports:
      - 7997:7997
    volumes:
      - /data/cache/huggingface:/cache/huggingface
    env_file:
      - ./infra/env.d/infinity
      - ./infra/env.d/huggingface
    command: ["v2"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: always
